{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bb356a1",
   "metadata": {},
   "source": [
    "#### Normal Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06632076",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "     def __init__(self, model, device, criterion, optimizer, early_stopping_patience, save_path, wscheduler=None):\n",
    "         self.model = model.to(device)\n",
    "         self.device = device\n",
    "         self.criterion = criterion\n",
    "         self.optimizer = optimizer\n",
    "         self.scheduler =scheduler\n",
    "         self.early_stopping_patience = early_stopping_patience\n",
    "         self.save_path = save_path\n",
    "         self.best_val_loss = 0.0\n",
    "         self.epochs_no_improve = 0\n",
    "\n",
    "     def train_one_epoch(self, train_loader):\n",
    "            self.model.train()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            correct, total = 0,0\n",
    "\n",
    "            for images, labels in tqdm(train_loader, desc=\"Training\", leave=False):\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(images)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * images.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (preds == labels).sum().item()\n",
    "\n",
    "            train_acc = 100 * correct / total\n",
    "            train_loss = running_loss / total\n",
    "\n",
    "            return train_loss, train_acc\n",
    "\n",
    "     def validate_per_epoch(self, val_loader):\n",
    "            val_loss, val_correct, val_total = 0.00, 0, 0\n",
    "            with torch.no_grad():\n",
    "                for images, labels in tqdm(val_loader, desc=\"Validation\"):\n",
    "                    images, labels = images.to(self.device), labels.to(self.device)\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    val_loss += loss.item() * images.size(0)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    val_total += labels.size(0)\n",
    "                    val_correct += (preds == labels).sum().item()\n",
    "\n",
    "            epoch_loss = val_loss/val_total\n",
    "            epoch_acc = 100 * val_correct / val_total\n",
    "\n",
    "            return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "     def fit(self, train_loader, val_loader, num_epochs):\n",
    "            history = {\"train_loss\": [], \"val_loss\": [], \"train_acc\": [], \"val_acc\": []}\n",
    "\n",
    "            for epoch in range(num_epochs):\n",
    "                print(f\"epochs {epoch}/{num_epochs}\")\n",
    "                train_loss, train_acc = self.train_one_epoch(train_loader)\n",
    "                val_loss, val_acc = self.validate_per_epoch(val_loader)\n",
    "\n",
    "                history[\"train_loss\"].append(train_loss)\n",
    "                history[\"train_acc\"].append(train_acc)\n",
    "                history[\"val_loss\"].append(val_loss)\n",
    "                history[\"val_acc\"].append(val_acc)\n",
    "\n",
    "                print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.2f}%\"\n",
    "                     f\"\\nValidation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.2f}%\")\n",
    "\n",
    "                if val_loss < self.best_val_loss:\n",
    "                    self.best_val_loss = val_loss\n",
    "                    self.save = f\"model/model-epoch{epoch}-best.pth\"\n",
    "                    torch.save(self.model.state_dict(), self.save_path)\n",
    "                    self.epochs_no_improve = 0\n",
    "                else:\n",
    "                    self.epochs_no_improve += 1\n",
    "                    if self.early_stopping_patience and self.epochs_no_improve > self.early_stopping_patience:\n",
    "                        self.save_path = \"model/finetuned-model.pth\"\n",
    "                        torch.save(self.model.state_dict(), self.save_path)\n",
    "                        print(f\"Early stopped latest model saved {self.save_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6577d016",
   "metadata": {},
   "source": [
    "#### Kfold-Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ecb178",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, device, criterion, optimizer, scheduler=None, \n",
    "                 early_stopping_patience=5, save_path=\"model/best_model.pth\"):\n",
    "        self.model = model.to(device)\n",
    "        self.device = device\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.early_stopping_patience = early_stopping_patience\n",
    "        self.save_path = save_path\n",
    "\n",
    "        self.best_val_loss = float(\"inf\")\n",
    "        self.epochs_no_improve = 0\n",
    "\n",
    "    def train_one_epoch(self, train_loader):\n",
    "        self.model.train()\n",
    "        running_loss = 0.0\n",
    "        correct, total = 0, 0\n",
    "\n",
    "        for images, labels in tqdm(train_loader, desc=\"Training\", leave=False):\n",
    "            images, labels = images.to(self.device), labels.to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            outputs = self.model(images)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "\n",
    "        train_acc = 100 * correct / total\n",
    "        train_loss = running_loss / total\n",
    "\n",
    "        return train_loss, train_acc\n",
    "\n",
    "    def validate_per_epoch(self, val_loader):\n",
    "        self.model.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(val_loader, desc=\"Validation\", leave=False):\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                outputs = self.model(images)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "\n",
    "        epoch_loss = val_loss / val_total\n",
    "        epoch_acc = 100 * val_correct / val_total\n",
    "        return epoch_loss, epoch_acc\n",
    "\n",
    "    def fit(self, train_loader, val_loader, num_epochs):\n",
    "        history = {\"train_loss\": [], \"val_loss\": [], \"train_acc\": [], \"val_acc\": []}\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "            train_loss, train_acc = self.train_one_epoch(train_loader)\n",
    "            val_loss, val_acc = self.validate_per_epoch(val_loader)\n",
    "\n",
    "            if self.scheduler:\n",
    "                self.scheduler.step(val_loss)\n",
    "\n",
    "            history[\"train_loss\"].append(train_loss)\n",
    "            history[\"train_acc\"].append(train_acc)\n",
    "            history[\"val_loss\"].append(val_loss)\n",
    "            history[\"val_acc\"].append(val_acc)\n",
    "\n",
    "            print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% | \"\n",
    "                  f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "            # --- Early Stopping ---\n",
    "            if val_loss < self.best_val_loss:\n",
    "                self.best_val_loss = val_loss\n",
    "                torch.save(self.model.state_dict(), self.save_path)\n",
    "                self.epochs_no_improve = 0\n",
    "                print(f\"✅ Best model saved at {self.save_path}\")\n",
    "            else:\n",
    "                self.epochs_no_improve += 1\n",
    "                if self.epochs_no_improve > self.early_stopping_patience:\n",
    "                    print(f\"⛔ Early Stopping triggered. Best model at {self.save_path}\")\n",
    "                    break\n",
    "\n",
    "        return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbf448a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainerKFold(model_class=MyModel, dataset=my_dataset).run()\n",
    "\n",
    "\n",
    "\n",
    "class TrainerKFold:\n",
    "    def __init__(self, model_class, dataset, device, criterion, optimizer_class,\n",
    "                 scheduler_class=None, n_splits=5, epochs=10, batch_size=32,\n",
    "                 patience=5, save_dir=\"model_kfold/\"):\n",
    "        self.model_class = model_class\n",
    "        self.dataset = dataset\n",
    "        self.device = device\n",
    "        self.criterion = criterion\n",
    "        self.optimizer_class = optimizer_class\n",
    "        self.scheduler_class = scheduler_class\n",
    "        self.n_splits = n_splits\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.patience = patience\n",
    "        self.save_dir = save_dir\n",
    "\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    def _get_targets(self):\n",
    "        if hasattr(self.dataset, \"targets\"):\n",
    "            return np.array(self.dataset.targets)\n",
    "        elif hasattr(self.dataset, \"labels\"):\n",
    "            return np.array(self.dataset.labels)\n",
    "        else:\n",
    "            raise ValueError(\"Dataset must have `.targets` or `.labels` attribute\")\n",
    "\n",
    "    def run(self):\n",
    "        y = self._get_targets()\n",
    "        skf = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=42)\n",
    "        fold_results = []\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(skf.split(np.zeros(len(y)), y)):\n",
    "            print(f\"\\n===== Fold {fold+1}/{self.n_splits} =====\")\n",
    "\n",
    "            train_subset = torch.utils.data.Subset(self.dataset, train_idx)\n",
    "            val_subset = torch.utils.data.Subset(self.dataset, val_idx)\n",
    "\n",
    "            train_loader = torch.utils.data.DataLoader(train_subset, batch_size=self.batch_size, shuffle=True)\n",
    "            val_loader = torch.utils.data.DataLoader(val_subset, batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "            model = self.model_class()\n",
    "            optimizer = self.optimizer_class(model.parameters(), lr=1e-4)\n",
    "            scheduler = None\n",
    "            if self.scheduler_class:\n",
    "                scheduler = self.scheduler_class(optimizer)\n",
    "\n",
    "            save_path = os.path.join(self.save_dir, f\"best_fold{fold+1}.pth\")\n",
    "            trainer = Trainer(model, self.device, self.criterion, optimizer, scheduler,\n",
    "                              early_stopping_patience=self.patience, save_path=save_path)\n",
    "\n",
    "            history = trainer.fit(train_loader, val_loader, self.epochs)\n",
    "            fold_results.append(history[\"val_acc\"][-1])\n",
    "\n",
    "        print(f\"\\nAverage Validation Accuracy across folds: {np.mean(fold_results):.2f}%\")\n",
    "        return fold_results\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
